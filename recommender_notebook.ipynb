{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-31T18:11:57.468297Z",
     "start_time": "2025-01-31T18:11:57.463680Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ast"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Data Exploration and Preprocessing\n",
   "id": "8f91b4babd1a89bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T13:53:07.326140Z",
     "start_time": "2025-01-31T13:52:57.390854Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the dataset\n",
    "credits = pd.read_csv('data/credits.csv')\n",
    "keywords = pd.read_csv('data/keywords.csv')\n",
    "links = pd.read_csv('data/links.csv')\n",
    "movies_metadata = pd.read_csv('data/movies_metadata.csv')\n",
    "ratings = pd.read_csv('data/ratings.csv')\n",
    "links_small = pd.read_csv('data/links_small.csv')"
   ],
   "id": "7ddcbc909aad5ea3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elden lord\\AppData\\Local\\Temp\\ipykernel_12284\\4068983867.py:5: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  movies_metadata = pd.read_csv('data/movies_metadata.csv')\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Analyzing Datasets",
   "id": "5239871731d7be28"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:53:14.341295Z",
     "start_time": "2025-01-31T00:53:14.287208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Movies Metadata:\")\n",
    "print(movies_metadata.info())\n",
    "print(movies_metadata.head(), \"\\n\")"
   ],
   "id": "4fee436e31bfb227",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies Metadata:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45466 entries, 0 to 45465\n",
      "Data columns (total 24 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   adult                  45466 non-null  object \n",
      " 1   belongs_to_collection  4494 non-null   object \n",
      " 2   budget                 45466 non-null  object \n",
      " 3   genres                 45466 non-null  object \n",
      " 4   homepage               7782 non-null   object \n",
      " 5   id                     45466 non-null  object \n",
      " 6   imdb_id                45449 non-null  object \n",
      " 7   original_language      45455 non-null  object \n",
      " 8   original_title         45466 non-null  object \n",
      " 9   overview               44512 non-null  object \n",
      " 10  popularity             45461 non-null  object \n",
      " 11  poster_path            45080 non-null  object \n",
      " 12  production_companies   45463 non-null  object \n",
      " 13  production_countries   45463 non-null  object \n",
      " 14  release_date           45379 non-null  object \n",
      " 15  revenue                45460 non-null  float64\n",
      " 16  runtime                45203 non-null  float64\n",
      " 17  spoken_languages       45460 non-null  object \n",
      " 18  status                 45379 non-null  object \n",
      " 19  tagline                20412 non-null  object \n",
      " 20  title                  45460 non-null  object \n",
      " 21  video                  45460 non-null  object \n",
      " 22  vote_average           45460 non-null  float64\n",
      " 23  vote_count             45460 non-null  float64\n",
      "dtypes: float64(4), object(20)\n",
      "memory usage: 8.3+ MB\n",
      "None\n",
      "   adult                              belongs_to_collection    budget  \\\n",
      "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
      "1  False                                                NaN  65000000   \n",
      "2  False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n",
      "3  False                                                NaN  16000000   \n",
      "4  False  {'id': 96871, 'name': 'Father of the Bride Col...         0   \n",
      "\n",
      "                                              genres  \\\n",
      "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
      "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
      "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n",
      "3  [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...   \n",
      "4                     [{'id': 35, 'name': 'Comedy'}]   \n",
      "\n",
      "                               homepage     id    imdb_id original_language  \\\n",
      "0  http://toystory.disney.com/toy-story    862  tt0114709                en   \n",
      "1                                   NaN   8844  tt0113497                en   \n",
      "2                                   NaN  15602  tt0113228                en   \n",
      "3                                   NaN  31357  tt0114885                en   \n",
      "4                                   NaN  11862  tt0113041                en   \n",
      "\n",
      "                original_title  \\\n",
      "0                    Toy Story   \n",
      "1                      Jumanji   \n",
      "2             Grumpier Old Men   \n",
      "3            Waiting to Exhale   \n",
      "4  Father of the Bride Part II   \n",
      "\n",
      "                                            overview  ... release_date  \\\n",
      "0  Led by Woody, Andy's toys live happily in his ...  ...   1995-10-30   \n",
      "1  When siblings Judy and Peter discover an encha...  ...   1995-12-15   \n",
      "2  A family wedding reignites the ancient feud be...  ...   1995-12-22   \n",
      "3  Cheated on, mistreated and stepped on, the wom...  ...   1995-12-22   \n",
      "4  Just when George Banks has recovered from his ...  ...   1995-02-10   \n",
      "\n",
      "       revenue runtime                                   spoken_languages  \\\n",
      "0  373554033.0    81.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
      "1  262797249.0   104.0  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...   \n",
      "2          0.0   101.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
      "3   81452156.0   127.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
      "4   76578911.0   106.0           [{'iso_639_1': 'en', 'name': 'English'}]   \n",
      "\n",
      "     status                                            tagline  \\\n",
      "0  Released                                                NaN   \n",
      "1  Released          Roll the dice and unleash the excitement!   \n",
      "2  Released  Still Yelling. Still Fighting. Still Ready for...   \n",
      "3  Released  Friends are the people who let you be yourself...   \n",
      "4  Released  Just When His World Is Back To Normal... He's ...   \n",
      "\n",
      "                         title  video vote_average vote_count  \n",
      "0                    Toy Story  False          7.7     5415.0  \n",
      "1                      Jumanji  False          6.9     2413.0  \n",
      "2             Grumpier Old Men  False          6.5       92.0  \n",
      "3            Waiting to Exhale  False          6.1       34.0  \n",
      "4  Father of the Bride Part II  False          5.7      173.0  \n",
      "\n",
      "[5 rows x 24 columns] \n",
      "\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:53:15.090640Z",
     "start_time": "2025-01-31T00:53:15.063167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Credits:\")\n",
    "print(credits.info())\n",
    "print(credits.head(), \"\\n\")"
   ],
   "id": "4991d22cb11087f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credits:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45476 entries, 0 to 45475\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   cast    45476 non-null  object\n",
      " 1   crew    45476 non-null  object\n",
      " 2   id      45476 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.0+ MB\n",
      "None\n",
      "                                                cast  \\\n",
      "0  [{'cast_id': 14, 'character': 'Woody (voice)',...   \n",
      "1  [{'cast_id': 1, 'character': 'Alan Parrish', '...   \n",
      "2  [{'cast_id': 2, 'character': 'Max Goldman', 'c...   \n",
      "3  [{'cast_id': 1, 'character': \"Savannah 'Vannah...   \n",
      "4  [{'cast_id': 1, 'character': 'George Banks', '...   \n",
      "\n",
      "                                                crew     id  \n",
      "0  [{'credit_id': '52fe4284c3a36847f8024f49', 'de...    862  \n",
      "1  [{'credit_id': '52fe44bfc3a36847f80a7cd1', 'de...   8844  \n",
      "2  [{'credit_id': '52fe466a9251416c75077a89', 'de...  15602  \n",
      "3  [{'credit_id': '52fe44779251416c91011acb', 'de...  31357  \n",
      "4  [{'credit_id': '52fe44959251416c75039ed7', 'de...  11862   \n",
      "\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:53:15.963079Z",
     "start_time": "2025-01-31T00:53:15.949793Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Keywords:\")\n",
    "print(keywords.info())\n",
    "print(keywords.head(), \"\\n\")"
   ],
   "id": "d5ac7c598ca25ac0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46419 entries, 0 to 46418\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        46419 non-null  int64 \n",
      " 1   keywords  46419 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 725.4+ KB\n",
      "None\n",
      "      id                                           keywords\n",
      "0    862  [{'id': 931, 'name': 'jealousy'}, {'id': 4290,...\n",
      "1   8844  [{'id': 10090, 'name': 'board game'}, {'id': 1...\n",
      "2  15602  [{'id': 1495, 'name': 'fishing'}, {'id': 12392...\n",
      "3  31357  [{'id': 818, 'name': 'based on novel'}, {'id':...\n",
      "4  11862  [{'id': 1009, 'name': 'baby'}, {'id': 1599, 'n... \n",
      "\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:53:16.740498Z",
     "start_time": "2025-01-31T00:53:16.730560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Ratings:\")\n",
    "print(ratings.info())\n",
    "print(ratings.head(), \"\\n\")"
   ],
   "id": "8fbae038375a4ad6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26024289 entries, 0 to 26024288\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   userId     int64  \n",
      " 1   movieId    int64  \n",
      " 2   rating     float64\n",
      " 3   timestamp  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 794.2 MB\n",
      "None\n",
      "   userId  movieId  rating   timestamp\n",
      "0       1      110     1.0  1425941529\n",
      "1       1      147     4.5  1425942435\n",
      "2       1      858     5.0  1425941523\n",
      "3       1     1221     5.0  1425941546\n",
      "4       1     1246     5.0  1425941556 \n",
      "\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Preprocessing",
   "id": "a1161bdccf20e7ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### convert IDs to numeric values to ensure that they are consistent",
   "id": "e599457d79fb5ea8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:53:43.170437Z",
     "start_time": "2025-01-31T00:53:43.132156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ensure that all IDs are numeric\n",
    "credits['id']  = pd.to_numeric(credits['id'],  errors='coerce')\n",
    "keywords['id'] = pd.to_numeric(keywords['id'], errors='coerce')\n",
    "links['tmdbId'] = pd.to_numeric(links['tmdbId'], errors='coerce')\n",
    "movies_metadata['id'] = pd.to_numeric(movies_metadata['id'], errors='coerce')"
   ],
   "id": "580b9b9eae351a53",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:53:45.834927Z",
     "start_time": "2025-01-31T00:53:45.713444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ensure that all IDs are numeric\n",
    "ratings['userId']  = pd.to_numeric(ratings['userId'],  errors='coerce')\n",
    "ratings['movieId'] = pd.to_numeric(ratings['movieId'], errors='coerce')\n",
    "ratings['rating']  = pd.to_numeric(ratings['rating'],  errors='coerce')"
   ],
   "id": "5f36e6f5a9681056",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### drop rows with missing IDs",
   "id": "f694a1e791d3759e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:53:49.002232Z",
     "start_time": "2025-01-31T00:53:48.172866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# drop rows with missing IDs\n",
    "movies_metadata.dropna(subset=['id'], inplace=True)\n",
    "credits.dropna(subset=['id'], inplace=True)\n",
    "keywords.dropna(subset=['id'], inplace=True)\n",
    "links.dropna(subset=['tmdbId'], inplace=True)\n",
    "ratings.dropna(subset=['movieId'], inplace=True)"
   ],
   "id": "d950672a12da7454",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### drop rows with duplicate IDs\n",
   "id": "973caa2a053c9bf7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:53:56.717445Z",
     "start_time": "2025-01-31T00:53:51.398434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "movies_metadata.drop_duplicates(subset='id', keep='first', inplace=True)\n",
    "credits.drop_duplicates(subset='id', keep='first', inplace=True)\n",
    "keywords.drop_duplicates(subset='id', keep='first', inplace=True)\n",
    "links.drop_duplicates(subset='tmdbId', keep='first', inplace=True)\n",
    "#a user might rate movie multiple times but we keep the first rating\n",
    "ratings.drop_duplicates(subset=['userId', 'movieId'], keep='first', inplace=True)\n"
   ],
   "id": "b24d23653f2d7ba9",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### preprocess movies metadata\n",
   "id": "f39853704727e767"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:54:01.507884Z",
     "start_time": "2025-01-31T00:54:01.502583Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def parse_jason(json_str):\n",
    "    try:\n",
    "        return ast.literal_eval(json_str) if pd.notnull(json_str) else None\n",
    "    except ValueError:\n",
    "        return None"
   ],
   "id": "7a3c54d495071a85",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### drop columns with more than 50% missing values\n",
    "since missing values are less than 1% we can drop them\n",
    "\n"
   ],
   "id": "4acbe8fe218e029e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:54:04.704884Z",
     "start_time": "2025-01-31T00:54:04.661647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#show missing percentage\n",
    "missing_movies_metadata = movies_metadata.isnull().sum()/len(movies_metadata)*100\n",
    "print(missing_movies_metadata)"
   ],
   "id": "d08f754eda977e6f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult                     0.000000\n",
      "belongs_to_collection    90.121718\n",
      "budget                    0.000000\n",
      "genres                    0.000000\n",
      "homepage                 82.889089\n",
      "id                        0.000000\n",
      "imdb_id                   0.037418\n",
      "original_language         0.024211\n",
      "original_title            0.000000\n",
      "overview                  2.099795\n",
      "popularity                0.006603\n",
      "poster_path               0.849603\n",
      "production_companies      0.006603\n",
      "production_countries      0.006603\n",
      "release_date              0.191491\n",
      "revenue                   0.006603\n",
      "runtime                   0.572271\n",
      "spoken_languages          0.006603\n",
      "status                    0.184888\n",
      "tagline                  55.096516\n",
      "title                     0.006603\n",
      "video                     0.006603\n",
      "vote_average              0.006603\n",
      "vote_count                0.006603\n",
      "dtype: float64\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:54:06.357543Z",
     "start_time": "2025-01-31T00:54:06.297446Z"
    }
   },
   "cell_type": "code",
   "source": [
    "movies_metadata.drop(columns=['homepage', 'belongs_to_collection','tagline'], inplace=True)\n",
    "movies_metadata.dropna(inplace=True)"
   ],
   "id": "10bfa82fa7010e53",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### handle json columns\n",
   "id": "70a1e0202f3011b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:54:17.841456Z",
     "start_time": "2025-01-31T00:54:08.286040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "json_columns = [\"genres\", \"spoken_languages\", \"production_companies\", \"production_countries\"]\n",
    "\n",
    "for column in json_columns:\n",
    "    movies_metadata[column] = movies_metadata[column].apply(\n",
    "        lambda x: [g[\"name\"] for g in parse_jason(x)] if isinstance(parse_jason(x), list) else []\n",
    "    )"
   ],
   "id": "15d73744692c028b",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### ensure correct data types",
   "id": "9645b239c9ef33db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:54:21.343111Z",
     "start_time": "2025-01-31T00:54:21.288285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "movies_metadata['budget'] = pd.to_numeric(movies_metadata['budget'], errors='coerce')\n",
    "movies_metadata['revenue'] = pd.to_numeric(movies_metadata['revenue'], errors='coerce')\n",
    "movies_metadata['popularity'] = pd.to_numeric(movies_metadata['popularity'], errors='coerce')\n",
    "movies_metadata['vote_average'] = pd.to_numeric(movies_metadata['vote_average'], errors='coerce')\n",
    "movies_metadata['vote_count'] = pd.to_numeric(movies_metadata['vote_count'], errors='coerce')\n",
    "movies_metadata['release_date'] = pd.to_datetime(movies_metadata['release_date'], errors='coerce')\n",
    "movies_metadata['runtime'] = pd.to_numeric(movies_metadata['runtime'], errors='coerce')"
   ],
   "id": "5e85f2edf516198e",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### save the preprocessed data to csv",
   "id": "7a421a7d037fe11f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:55:21.542986Z",
     "start_time": "2025-01-31T00:55:20.770924Z"
    }
   },
   "cell_type": "code",
   "source": "movies_metadata.to_csv('movies_metadata_preprocessed.csv', index=False)",
   "id": "c0c54378200964dd",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### preprocess credits",
   "id": "c6304ce36853fca3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### there is no missing values in the credits dataset",
   "id": "519d6ded254110c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:55:23.731745Z",
     "start_time": "2025-01-31T00:55:23.712618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "missing_percentage = credits.isnull().sum() / len(credits) * 100\n",
    "print(missing_percentage)"
   ],
   "id": "682c4809a3538d5e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cast    0.0\n",
      "crew    0.0\n",
      "id      0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### handle json columns",
   "id": "6a9828c99bc9cd2d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:56:50.700325Z",
     "start_time": "2025-01-31T00:55:26.113580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "json_columns = [\"cast\", \"crew\"]\n",
    "for column in json_columns:\n",
    "    credits[column] = credits[column].apply(\n",
    "        lambda x: [g[\"name\"] for g in parse_jason(x)] if isinstance(parse_jason(x), list) else []\n",
    "    )"
   ],
   "id": "260d942e30d785f6",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:57:55.746895Z",
     "start_time": "2025-01-31T00:57:55.171299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "credits.to_csv(\"cleaned_movie_credits.csv\", index=False)\n",
    "credits.head()"
   ],
   "id": "cf434744807ac1ea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                cast  \\\n",
       "0  [Tom Hanks, Tim Allen, Don Rickles, Jim Varney...   \n",
       "1  [Robin Williams, Jonathan Hyde, Kirsten Dunst,...   \n",
       "2  [Walter Matthau, Jack Lemmon, Ann-Margret, Sop...   \n",
       "3  [Whitney Houston, Angela Bassett, Loretta Devi...   \n",
       "4  [Steve Martin, Diane Keaton, Martin Short, Kim...   \n",
       "\n",
       "                                                crew     id  \n",
       "0  [John Lasseter, Joss Whedon, Andrew Stanton, J...    862  \n",
       "1  [Larry J. Franco, Jonathan Hensleigh, James Ho...   8844  \n",
       "2  [Howard Deutch, Mark Steven Johnson, Mark Stev...  15602  \n",
       "3  [Forest Whitaker, Ronald Bass, Ronald Bass, Ez...  31357  \n",
       "4  [Alan Silvestri, Elliot Davis, Nancy Meyers, N...  11862  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Tom Hanks, Tim Allen, Don Rickles, Jim Varney...</td>\n",
       "      <td>[John Lasseter, Joss Whedon, Andrew Stanton, J...</td>\n",
       "      <td>862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Robin Williams, Jonathan Hyde, Kirsten Dunst,...</td>\n",
       "      <td>[Larry J. Franco, Jonathan Hensleigh, James Ho...</td>\n",
       "      <td>8844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Walter Matthau, Jack Lemmon, Ann-Margret, Sop...</td>\n",
       "      <td>[Howard Deutch, Mark Steven Johnson, Mark Stev...</td>\n",
       "      <td>15602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Whitney Houston, Angela Bassett, Loretta Devi...</td>\n",
       "      <td>[Forest Whitaker, Ronald Bass, Ronald Bass, Ez...</td>\n",
       "      <td>31357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Steve Martin, Diane Keaton, Martin Short, Kim...</td>\n",
       "      <td>[Alan Silvestri, Elliot Davis, Nancy Meyers, N...</td>\n",
       "      <td>11862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### preprocess keywords\n",
   "id": "dcbd6a97efdfa464"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### there is no missing values in the keywords dataset\n",
   "id": "576ef03fe620ce8e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:58:03.231109Z",
     "start_time": "2025-01-31T00:58:03.221131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "missing_percentage = keywords.isnull().sum() / len(keywords) * 100\n",
    "print(missing_percentage)"
   ],
   "id": "b1960bf119ac7bb0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id          0.0\n",
      "keywords    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### handle json columns",
   "id": "dd56cfdef79b1db8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:58:11.300874Z",
     "start_time": "2025-01-31T00:58:06.256190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "json_columns = [\"keywords\"]\n",
    "for column in json_columns:\n",
    "    keywords[column] = keywords[column].apply(\n",
    "        lambda x: [g[\"name\"] for g in parse_jason(x)] if isinstance(parse_jason(x), list) else []\n",
    "    )\n"
   ],
   "id": "1c2f701cc231d013",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:58:16.004872Z",
     "start_time": "2025-01-31T00:58:15.867299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "keywords.to_csv(\"cleaned_movie_keywords.csv\", index=False)\n",
    "keywords.head()"
   ],
   "id": "64d007c1c5af6d60",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      id                                           keywords\n",
       "0    862  [jealousy, toy, boy, friendship, friends, riva...\n",
       "1   8844  [board game, disappearance, based on children'...\n",
       "2  15602  [fishing, best friend, duringcreditsstinger, o...\n",
       "3  31357  [based on novel, interracial relationship, sin...\n",
       "4  11862  [baby, midlife crisis, confidence, aging, daug..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>862</td>\n",
       "      <td>[jealousy, toy, boy, friendship, friends, riva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8844</td>\n",
       "      <td>[board game, disappearance, based on children'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15602</td>\n",
       "      <td>[fishing, best friend, duringcreditsstinger, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31357</td>\n",
       "      <td>[based on novel, interracial relationship, sin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11862</td>\n",
       "      <td>[baby, midlife crisis, confidence, aging, daug...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### preprocess links\n",
    "#### links are clean so no change is needed"
   ],
   "id": "1df90f1f8c02247a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:59:41.159179Z",
     "start_time": "2025-01-31T00:59:41.151963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "missing_percentage = links.isnull().sum() / len(links) * 100\n",
    "print(missing_percentage)"
   ],
   "id": "efe6c4cfc764a0f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movieId    0.0\n",
      "imdbId     0.0\n",
      "tmdbId     0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### preprocess ratings\n",
   "id": "f1093784dd7a8e77"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:59:53.279827Z",
     "start_time": "2025-01-31T00:59:53.139474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "missing_percentage = ratings.isnull().sum() / len(ratings) * 100\n",
    "print(missing_percentage)"
   ],
   "id": "c949cd56c6bbf72c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId       0.0\n",
      "movieId      0.0\n",
      "rating       0.0\n",
      "timestamp    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### ensure correct data types",
   "id": "5ecfe2aa5a69e5a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T00:59:58.290775Z",
     "start_time": "2025-01-31T00:59:56.109118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ratings['timestamp'] = pd.to_datetime(ratings['timestamp'], unit='s')\n",
    "ratings['rating'] = pd.to_numeric(ratings['rating'], errors='coerce')\n",
    "ratings['userId'] = pd.to_numeric(ratings['userId'], errors='coerce')\n",
    "ratings['movieId'] = pd.to_numeric(ratings['movieId'], errors='coerce')"
   ],
   "id": "7dbddeab356aa939",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T01:01:12.231386Z",
     "start_time": "2025-01-31T00:59:59.872719Z"
    }
   },
   "cell_type": "code",
   "source": "ratings.to_csv(\"cleaned_ratings.csv\", index=False)",
   "id": "33d1d9c690d65340",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Implement Recommender System",
   "id": "58209e16cd86f457"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T18:12:13.132139Z",
     "start_time": "2025-01-31T18:12:09.712495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import os\n",
    "import torch_directml\n",
    "\n"
   ],
   "id": "c42fdf93d9ab6ce",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T18:12:15.149055Z",
     "start_time": "2025-01-31T18:12:15.134071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n"
   ],
   "id": "64e73aa970f0853f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1709d522dd0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load and prepare the preprocessed data",
   "id": "fdd239dae514158c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load the preprocessed data",
   "id": "27c5ddb11472876"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T18:12:18.705410Z",
     "start_time": "2025-01-31T18:12:17.891385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ratings_df = pd.read_csv(\"data/ratings_small.csv\")\n",
    "movies_metadata_df = pd.read_csv(\"movies_metadata_preprocessed.csv\")\n",
    "keywords_df = pd.read_csv(\"cleaned_movie_keywords.csv\")\n",
    "credits_df = pd.read_csv(\"cleaned_movie_credits.csv\")"
   ],
   "id": "6d1b0bff318ab8c1",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Prepare the data\n",
    "#### for computational efficiency, we will consider ratings more than 2 = 1 and under that zero"
   ],
   "id": "187f735981393c7a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T18:12:19.964343Z",
     "start_time": "2025-01-31T18:12:19.931513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ratings_df['implicit'] = (ratings_df['rating'] >= 3).astype(int)\n",
    "ratings_df.sort_values(by=['userId', 'timestamp'], inplace=True)\n",
    "ratings_df.reset_index(drop=True, inplace=True)"
   ],
   "id": "b81606a52bf7fb84",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### merge dataframes\n",
    "#### change id to movieId in datasets for merging"
   ],
   "id": "15763539d468839"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T18:12:21.694050Z",
     "start_time": "2025-01-31T18:12:21.689002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "keywords_df.rename(columns={'id':'movieId'}, inplace=True)\n",
    "credits_df.rename(columns={'id':'movieId'}, inplace=True)\n",
    "movies_metadata_df.rename(columns={'id':'movieId'}, inplace=True)\n"
   ],
   "id": "71801e76aac450ae",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### merge the datasets",
   "id": "ff6824690356c3b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T18:12:23.383718Z",
     "start_time": "2025-01-31T18:12:23.330381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "movie_content_df = movies_metadata_df.merge(keywords_df, on='movieId', how='left')\n",
    "movie_content_df = movie_content_df.merge(credits_df, on='movieId', how='left')\n"
   ],
   "id": "726c9fdd910b7a04",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Build User-Sequence Documents",
   "id": "ff407579a197e726"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### build user index mappings",
   "id": "f7086cd0b114ecc0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T18:12:25.622633Z",
     "start_time": "2025-01-31T18:12:25.612409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "unique_users = ratings_df['userId'].unique()\n",
    "user2index = {u: i for i, u in enumerate(unique_users)}\n",
    "index2user = {i: u for u, i in user2index.items()}\n",
    "num_users = len(unique_users)\n",
    "\n",
    "unique_items = ratings_df['movieId'].unique()\n",
    "item2index = {m: i for i, m in enumerate(unique_items)}\n",
    "index2item = {i: m for m, i in item2index.items()}\n",
    "num_items = len(unique_items)"
   ],
   "id": "9151f6369e8ab214",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### build user sequences",
   "id": "d8896ef684a920dc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### make user sequences",
   "id": "7254bbca5377cb4d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T18:12:28.347869Z",
     "start_time": "2025-01-31T18:12:28.056372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_sequences = {}\n",
    "for row in ratings_df.itertuples():\n",
    "    u = getattr(row, 'userId')\n",
    "    i = getattr(row, 'movieId')\n",
    "    user_sequences.setdefault(u, []).append(str(i))\n",
    "\n",
    "tagged_docs = []\n",
    "for u, item_list in user_sequences.items():\n",
    "        tagged_docs.append(TaggedDocument(words=item_list, tags=[str(u)]))  # for each user interaction\n"
   ],
   "id": "5c72523ffd66f304",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train Doc2Vec Model for user sequences",
   "id": "b43aabace6acb60b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T18:12:31.058929Z",
     "start_time": "2025-01-31T18:12:30.306216Z"
    }
   },
   "cell_type": "code",
   "source": [
    "d2v_vector_size = 40\n",
    "d2v_window = 10\n",
    "d2v_model = Doc2Vec(\n",
    "    documents=tagged_docs,\n",
    "    vector_size=d2v_vector_size,\n",
    "    window=d2v_window,\n",
    "    min_count=1,\n",
    "    dm=0,\n",
    "    epochs=10,\n",
    "    workers=4\n",
    ")"
   ],
   "id": "dbb1389ac6879644",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Build user docvec and item wordvec documents",
   "id": "b71e2d0f9e6046db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T18:12:33.330191Z",
     "start_time": "2025-01-31T18:12:33.298873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_docvec_map = {}\n",
    "for u in unique_users:\n",
    "    user_docvec_map[u] = d2v_model.dv[str(u)]\n",
    "\n",
    "item_wordvec_map = {}\n",
    "for m in unique_items:\n",
    "    if str(m) in d2v_model.wv:\n",
    "        item_wordvec_map[m] = d2v_model.wv[str(m)]\n",
    "    else:\n",
    "        item_wordvec_map[m] = np.zeros(d2v_vector_size)\n"
   ],
   "id": "877565a31f27c97c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Build item-content documents",
   "id": "401dfec328dcdadc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T18:12:35.059982Z",
     "start_time": "2025-01-31T18:12:35.055105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def list_to_str(lst):\n",
    "    if not isinstance(lst, list):\n",
    "        return \"\"\n",
    "    return \" \".join(str(x) for x in lst)\n",
    "safe_str = lambda x: x if pd.notnull(x) else \"\""
   ],
   "id": "a2046c0a3826f8a1",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Preprocess and combine fields\n",
   "id": "880c6518fbae2186"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T18:12:41.391804Z",
     "start_time": "2025-01-31T18:12:36.665171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "item_content_docs = []\n",
    "for row in movie_content_df.itertuples(index=False):\n",
    "    mid = row.movieId\n",
    "    overview_text = safe_str(row.overview)\n",
    "\n",
    "    keywords_text = list_to_str(eval(row.keywords)) if isinstance(row.keywords, str) else list_to_str(row.keywords)\n",
    "    cast_text = list_to_str(eval(row.cast)) if isinstance(row.cast, str) else list_to_str(row.cast)\n",
    "    crew_text = list_to_str(eval(row.crew)) if isinstance(row.crew, str) else list_to_str(row.crew)\n",
    "    # merge them all\n",
    "    combined_content = (\n",
    "        overview_text + \" \" +\n",
    "        keywords_text + \" \" +\n",
    "        cast_text + \" \" +\n",
    "        crew_text\n",
    "    )\n",
    "    item_content_docs.append(TaggedDocument(\n",
    "        words=combined_content.lower().split(),\n",
    "        tags=[f\"ITEM_{int(mid)}\"]\n",
    "    ))\n"
   ],
   "id": "abf071474959d12b",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train Doc2Vec model for item content",
   "id": "42e6dd80cd3dc500"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T18:13:23.702895Z",
     "start_time": "2025-01-31T18:12:43.598910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "content_vector_size = 40\n",
    "item_content_model = Doc2Vec(\n",
    "    documents=item_content_docs,\n",
    "    vector_size=content_vector_size,\n",
    "    window=10,\n",
    "    min_count=1,\n",
    "    dm=0,\n",
    "    epochs=10,\n",
    "    workers=4\n",
    ")\n",
    "\n",
    "item_content_map = {}\n",
    "for row in movie_content_df.itertuples(index=False):\n",
    "    mid = row.movieId\n",
    "    # if it didn't appear in doc2vec, default to zeros\n",
    "    tag_id = f\"ITEM_{int(mid)}\"\n",
    "    if tag_id in item_content_model.dv:\n",
    "        item_content_map[mid] = item_content_model.dv[tag_id]\n",
    "    else:\n",
    "        item_content_map[mid] = np.zeros(content_vector_size)\n"
   ],
   "id": "f3bf0060f0ac88ee",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Build the DSER Model\n",
    "### Define GMF"
   ],
   "id": "210636fa4003c946"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T18:13:50.240766Z",
     "start_time": "2025-01-31T18:13:50.234088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GMF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_size=8):\n",
    "        super(GMF, self).__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, emb_size)\n",
    "        self.item_emb = nn.Embedding(num_items, emb_size)\n",
    "        nn.init.xavier_uniform_(self.user_emb.weight)\n",
    "        nn.init.xavier_uniform_(self.item_emb.weight)\n",
    "\n",
    "    def forward(self, user_idx, item_idx):\n",
    "        u = self.user_emb(user_idx)\n",
    "        i = self.item_emb(item_idx)\n",
    "        return u * i"
   ],
   "id": "88ebd4a4bfa40e3b",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define MLP",
   "id": "d186415bcb20270a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T18:13:51.828429Z",
     "start_time": "2025-01-31T18:13:51.823054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim=120, layers=[64,32,16]):\n",
    "        super(MLP, self).__init__()\n",
    "        seq = []\n",
    "        prev_dim = input_dim\n",
    "        for layer_size in layers:\n",
    "            seq.append(nn.Linear(prev_dim, layer_size))\n",
    "            seq.append(nn.ReLU())\n",
    "            prev_dim = layer_size\n",
    "        self.mlp = nn.Sequential(*seq)\n",
    "\n",
    "    def forward(self, user_doc, item_word, item_content):\n",
    "        x = torch.cat((user_doc, item_word, item_content), dim=1)\n",
    "        out = self.mlp(x)\n",
    "        return out"
   ],
   "id": "7abbe1ab80830521",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Define DSER",
   "id": "14d40b8ec526c130"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T18:13:54.163812Z",
     "start_time": "2025-01-31T18:13:54.157672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DSER(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_users,\n",
    "                 num_items,\n",
    "                 gmf_emb_size=8,\n",
    "                 mlp_input_dim=120,\n",
    "                 mlp_layers=[64, 32, 16]):\n",
    "        super(DSER, self).__init__()\n",
    "        self.gmf = GMF(num_users, num_items, emb_size=gmf_emb_size)\n",
    "        self.mlp = MLP(input_dim=mlp_input_dim, layers=mlp_layers)\n",
    "\n",
    "        final_dim = gmf_emb_size + mlp_layers[-1]\n",
    "        self.out = nn.Linear(final_dim, 1)\n",
    "        nn.init.xavier_uniform_(self.out.weight)\n",
    "\n",
    "    def forward(self,\n",
    "                user_idx, item_idx,\n",
    "                user_docvec, item_wordvec, item_contentvec):\n",
    "        # GMF part\n",
    "        gmf_vec = self.gmf(user_idx, item_idx)\n",
    "        # MLP part\n",
    "        mlp_vec = self.mlp(user_docvec, item_wordvec, item_contentvec)\n",
    "\n",
    "        # Fusion\n",
    "        concat = torch.cat([gmf_vec, mlp_vec], dim=1)\n",
    "        logit = self.out(concat).squeeze(-1)\n",
    "        return torch.sigmoid(logit)\n"
   ],
   "id": "698b64aa142f91d6",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train/Test split with navigate sampeling",
   "id": "f376bc7ec0472ec2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### shuffle and split the datas 80/20",
   "id": "4ddd94397811b25d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T18:13:57.323392Z",
     "start_time": "2025-01-31T18:13:57.301396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_data = ratings_df[['userId','movieId','rating']].drop_duplicates()\n",
    "all_data = all_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "split_idx = int(0.8 * len(all_data))\n",
    "train_df = all_data.iloc[:split_idx]\n",
    "test_df  = all_data.iloc[split_idx:]\n"
   ],
   "id": "fac9a12f17dc27d2",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T18:13:59.353736Z",
     "start_time": "2025-01-31T18:13:59.303543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_ui_set = set(zip(all_data['userId'], all_data['movieId']))\n",
    "\n",
    "len_ui_set = len(all_ui_set)\n",
    "print(\"Size of all_ui_set:\", len_ui_set)"
   ],
   "id": "73709f6abd7655ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of all_ui_set: 100004\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### negative sampling\n",
    "#### store all user-item pairs in a set to avoid duplicating"
   ],
   "id": "6e655de5ac770410"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T18:14:00.989785Z",
     "start_time": "2025-01-31T18:14:00.924637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_ui_set = set(zip(all_data['userId'], all_data['movieId']))\n",
    "train_pos = train_df[train_df['rating']==1]"
   ],
   "id": "a1e9536402ca9ab7",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### create negative samples\n",
    "#### sample 4 negative samples for each positive sample"
   ],
   "id": "9d4b597b6b6be187"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T18:14:02.932343Z",
     "start_time": "2025-01-31T18:14:02.883368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_instances = []\n",
    "neg_ratio = 4\n",
    "for row in train_pos.itertuples(index=False):\n",
    "    u = row.userId\n",
    "    m = row.movieId\n",
    "    # positive samples\n",
    "    train_instances.append((u, m, 1))\n",
    "    # negative samples\n",
    "    for _ in range(neg_ratio):\n",
    "        neg_item = random.choice(unique_items)\n",
    "        while (u, neg_item) in all_ui_set:\n",
    "            neg_item = random.choice(unique_items)\n",
    "        train_instances.append((u, neg_item, 0))\n",
    "\n",
    "train_np = np.array(train_instances, dtype=np.int64)"
   ],
   "id": "a1c0777265044cfd",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Set the gpu device\n",
    "#### if your device has additional graphic, better switch to it"
   ],
   "id": "242929d700abd811"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T18:14:05.064448Z",
     "start_time": "2025-01-31T18:14:04.653619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_gpus = torch_directml.device_count()\n",
    "for i in range(num_gpus):\n",
    "    print(f\"GPU {i}: {torch_directml.device_name(i)}\")"
   ],
   "id": "2b392efc7d5fcef1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: AMD Radeon RX 6800S\u0000\n",
      "GPU 1: AMD Radeon(TM) Graphics\u0000\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T18:14:05.856687Z",
     "start_time": "2025-01-31T18:14:05.853444Z"
    }
   },
   "cell_type": "code",
   "source": "device = torch_directml.device(0)",
   "id": "974a150a4ee6ff3b",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### train DSER Model\n",
    "#### Hyperparameters"
   ],
   "id": "2fb15fea75e3164c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T18:14:09.019084Z",
     "start_time": "2025-01-31T18:14:07.682281Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gmf_emb_size = 8\n",
    "mlp_input_dim = 40 + 40 + 40\n",
    "mlp_layers = [64, 32, 16]\n",
    "\n",
    "model = DSER(num_users=num_users,\n",
    "             num_items=num_items,\n",
    "             gmf_emb_size=gmf_emb_size,\n",
    "             mlp_input_dim=mlp_input_dim,\n",
    "             mlp_layers=mlp_layers).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.BCELoss()\n",
    "\n"
   ],
   "id": "47d77bb60f4412c9",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Training Loop",
   "id": "fdb89b9003fd03d4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T18:14:18.334755Z",
     "start_time": "2025-01-31T18:14:10.840064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "for ep in range(EPOCHS):\n",
    "    np.random.shuffle(train_np)\n",
    "    epoch_loss = 0.0\n",
    "    model.train()\n",
    "\n",
    "    for start in range(0, len(train_np), BATCH_SIZE):\n",
    "        end = min(start + BATCH_SIZE, len(train_np))\n",
    "        batch = train_np[start:end]\n",
    "\n",
    "        user_list = batch[:, 0]\n",
    "        item_list = batch[:, 1]\n",
    "        label_list = batch[:, 2]\n",
    "\n",
    "        # make torch Tensors\n",
    "        user_idx = torch.LongTensor([user2index[u] for u in user_list]).to(device)\n",
    "        item_idx = torch.LongTensor([item2index[i] for i in item_list]).to(device)\n",
    "        y_batch  = torch.FloatTensor(label_list).to(device)\n",
    "\n",
    "        # build doc2vec input\n",
    "        user_vecs = [user_docvec_map[u] for u in user_list]\n",
    "        item_seq_vecs = [item_wordvec_map[i] for i in item_list]\n",
    "        default_content_vec = np.zeros(content_vector_size, dtype=np.float32)\n",
    "        item_cnt_vecs = []\n",
    "        for i in item_list:\n",
    "            if i in item_content_map:\n",
    "                item_cnt_vecs.append(item_content_map[i])\n",
    "            else:\n",
    "                item_cnt_vecs.append(default_content_vec)\n",
    "\n",
    "        user_vec_t = torch.FloatTensor(user_vecs).to(device)\n",
    "        item_seq_t = torch.FloatTensor(item_seq_vecs).to(device)\n",
    "        item_cnt_t = torch.FloatTensor(item_cnt_vecs).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(user_idx, item_idx, user_vec_t, item_seq_t, item_cnt_t)\n",
    "        loss = criterion(predictions, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {ep+1}/{EPOCHS}, Loss = {epoch_loss:.4f}\")\n"
   ],
   "id": "d4a48435afa01ed4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elden lord\\AppData\\Local\\Temp\\ipykernel_8528\\3318148175.py:33: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  user_vec_t = torch.FloatTensor(user_vecs).to(device)\n",
      "D:\\Anaconda\\envs\\final_project_ml\\Lib\\site-packages\\torch\\nn\\functional.py:3172: UserWarning: The operator 'aten::binary_cross_entropy' is not currently supported on the DML backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at C:\\__w\\1\\s\\pytorch-directml-plugin\\torch_directml\\csrc\\dml\\dml_cpu_fallback.cpp:17.)\n",
      "  return torch._C._nn.binary_cross_entropy(input, target, weight, reduction_enum)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss = 13.6784\n",
      "Epoch 2/10, Loss = 12.5869\n",
      "Epoch 3/10, Loss = 10.9542\n",
      "Epoch 4/10, Loss = 6.7213\n",
      "Epoch 5/10, Loss = 2.9933\n",
      "Epoch 6/10, Loss = 1.4208\n",
      "Epoch 7/10, Loss = 0.7933\n",
      "Epoch 8/10, Loss = 0.4954\n",
      "Epoch 9/10, Loss = 0.3356\n",
      "Epoch 10/10, Loss = 0.2405\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Recommend for user function",
   "id": "d80c2e8421a551ce"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T18:14:21.753161Z",
     "start_time": "2025-01-31T18:14:21.746198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def recommend_for_user(user_id, topK=5):\n",
    "    model.eval()\n",
    "    if user_id not in user_docvec_map:\n",
    "        print(f\"No user embedding for {user_id}. Returning empty.\")\n",
    "        return []\n",
    "\n",
    "    user_idx = user2index[user_id]\n",
    "    user_doc = user_docvec_map[user_id]\n",
    "    user_doc_t = torch.FloatTensor(user_doc.copy()).unsqueeze(0).to(device)\n",
    "\n",
    "    default_content_vec = np.zeros(content_vector_size, dtype=np.float32)\n",
    "\n",
    "    scores = []\n",
    "    for it in unique_items:\n",
    "        it_idx = item2index[it]\n",
    "\n",
    "        item_seq_vec = item_wordvec_map[it]\n",
    "        if it in item_content_map:\n",
    "            item_cnt_vec = item_content_map[it]\n",
    "        else:\n",
    "            item_cnt_vec = default_content_vec\n",
    "\n",
    "        u_batch = torch.LongTensor([user_idx]).to(device)\n",
    "        i_batch = torch.LongTensor([it_idx]).to(device)\n",
    "\n",
    "        item_seq_t = torch.FloatTensor(item_seq_vec.copy()).unsqueeze(0).to(device)\n",
    "        item_cnt_t = torch.FloatTensor(item_cnt_vec.copy()).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            score = model(u_batch, i_batch, user_doc_t, item_seq_t, item_cnt_t).item()\n",
    "\n",
    "        scores.append((it, score))\n",
    "\n",
    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    return scores[:topK]\n",
    "\n",
    "\n"
   ],
   "id": "64f9c1210ecb1a40",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T18:17:11.663806Z",
     "start_time": "2025-01-31T18:17:01.777597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "id2title = dict(zip(movies_metadata_df['movieId'], movies_metadata_df['title']))\n",
    "some_user_id = unique_users[5]\n",
    "print(f\"Top-5 items for user {some_user_id}:\")\n",
    "top_items = recommend_for_user(some_user_id, topK=5)\n",
    "for movie_id, s in top_items:\n",
    "    movie_title = id2title.get(movie_id, \"Unknown Title\")\n",
    "    print(f\"MovieID={movie_id} | Title={movie_title} | Score={s:.4f}\")"
   ],
   "id": "bc940783d4cd56de",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 items for user 6:\n",
      "MovieID=1562 | Title=28 Weeks Later | Score=0.9989\n",
      "MovieID=3977 | Title=Unknown Title | Score=0.9969\n",
      "MovieID=2710 | Title=Unknown Title | Score=0.9959\n",
      "MovieID=1917 | Title=Who Killed Bambi? | Score=0.9950\n",
      "MovieID=19 | Title=Metropolis | Score=0.9941\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluate Recommender System",
   "id": "41e55bde67dad6b0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T18:23:00.986196Z",
     "start_time": "2025-01-31T18:23:00.976144Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def evaluate_recommender(model, device,\n",
    "                  test_df, user2index, item2index,\n",
    "                  user_docvec_map, item_wordvec_map, item_content_map,\n",
    "                  K=10,\n",
    "                  content_vector_size=40):\n",
    "    model.eval()\n",
    "    all_ui_set = set(zip(test_df['userId'], test_df['movieId']))\n",
    "\n",
    "    hits_sum = 0.0\n",
    "    ndcgs_sum= 0.0\n",
    "    total_count = 0\n",
    "    for row in test_df.itertuples(index=False):\n",
    "        u, item, implicit_val = row.userId, row.movieId, row.implicit\n",
    "        if implicit_val != 1:\n",
    "            continue\n",
    "\n",
    "        total_count += 1\n",
    "        neg_candidates = []\n",
    "        tries = 0\n",
    "        while len(neg_candidates) < 19 and tries<1000:\n",
    "            neg_item = random.choice(list(item2index.keys()))\n",
    "            if neg_item == item:\n",
    "                tries +=1\n",
    "                continue\n",
    "            if (u, neg_item) not in all_ui_set:\n",
    "                neg_candidates.append(neg_item)\n",
    "            tries +=1\n",
    "\n",
    "        test_items = [item] + neg_candidates\n",
    "\n",
    "        user_idx = torch.LongTensor([user2index[u]]).to(device)\n",
    "        user_doc = user_docvec_map[u].copy()\n",
    "\n",
    "        user_doc_t = torch.FloatTensor(user_doc).unsqueeze(0).to(device)\n",
    "\n",
    "        scores_list = []\n",
    "        for itm in test_items:\n",
    "            i_idx = torch.LongTensor([item2index[itm]]).to(device)\n",
    "\n",
    "            seq_vec = item_wordvec_map[itm].copy()\n",
    "            item_seq_t = torch.FloatTensor(seq_vec).unsqueeze(0).to(device)\n",
    "\n",
    "            if itm in item_content_map:\n",
    "                cnt_vec = item_content_map[itm].copy()\n",
    "            else:\n",
    "                cnt_vec = np.zeros(content_vector_size, dtype=np.float32)\n",
    "            item_cnt_t = torch.FloatTensor(cnt_vec).unsqueeze(0).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                score = model(user_idx, i_idx,\n",
    "                              user_doc_t, item_seq_t, item_cnt_t).item()\n",
    "\n",
    "            scores_list.append((itm, score))\n",
    "\n",
    "        scores_list.sort(key=lambda x:x[1], reverse=True)\n",
    "\n",
    "        rank = 0\n",
    "        for idx,(itm, sc) in enumerate(scores_list):\n",
    "            if itm == item:\n",
    "                rank = idx\n",
    "                break\n",
    "\n",
    "\n",
    "        if rank < K:\n",
    "            hits_sum += 1.0\n",
    "            ndcgs_sum += 1.0 / math.log2(rank+2)\n",
    "    hr = hits_sum / total_count if total_count>0 else 0\n",
    "    ndcg = ndcgs_sum / total_count if total_count>0 else 0\n",
    "    return hr, ndcg"
   ],
   "id": "c8ce6d72b48f2bab",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-31T18:29:12.664320Z",
     "start_time": "2025-01-31T18:23:01.739178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_df = test_df.copy()\n",
    "if 'rating' in test_df.columns and 'implicit' not in test_df.columns:\n",
    "    test_df['implicit'] = (test_df['rating'] >= 3).astype(int)\n",
    "\n",
    "hr10, ndcg10 = evaluate_recommender(\n",
    "    model=model,\n",
    "    device=device,\n",
    "    test_df=test_df,\n",
    "    user2index=user2index,\n",
    "    item2index=item2index,\n",
    "    user_docvec_map=user_docvec_map,\n",
    "    item_wordvec_map=item_wordvec_map,\n",
    "    item_content_map=item_content_map,\n",
    "    K=10,  # Evaluate top-10\n",
    "    content_vector_size=40\n",
    ")\n",
    "\n",
    "print(f\"HR@10={hr10:.4f}, NDCG@10={ndcg10:.4f}\")"
   ],
   "id": "6a02e9e481a0f951",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HR@10=0.5816, NDCG@10=0.2934\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ec07118fa3e464a3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
